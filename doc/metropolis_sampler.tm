<TeXmacs|1.99.5>

<style|generic>

<\body>
  This documentation provides an illustration (and also a proof) of
  Metropolis sampler. The proof follows Metropolis et al (1953), but is
  modified and generalized in its morden face.

  <\notation>
    Let <math|x\<in\><with|math-font|cal|X>> any state of a given stochastic
    system. Let <math|p<around*|(|x|)>> denotes the target distribution to be
    mimicked. Let <math|P<rsub|x,y>> the proposed transition-distribution of
    Markov process from state <math|x> to <math|y> (i.e. the \Ppriori\Q in
    Metropolis et al (1953)), where <math|P<rsub|x,y>=P<rsub|y,x>> as
    demanded by Metripolis algorithm.
  </notation>

  <\algorithm>
    <label|algorithm: Metropolis>[Metropolis]

    <\enumerate-numeric>
      <item>Initialize <verbatim|chain = []> and <verbatim|accepted = 0>;

      <item>randomly initialized state <math|x<rsub|0>\<in\><with|math-font|cal|X>>;

      <item>for <verbatim|i> in <verbatim|iterations>:

      <\enumerate-numeric>
        <item>sampling <math|x<rsub|i+1>> from <math|x<rsub|i>> by Markov
        process characterized by <math|P<rsub|x<rsub|i>,x<rsub|i+1>>>;

        <item>compute <math|\<alpha\>\<assign\>p<around*|(|x<rsub|i+1>|)>/p<around*|(|x<rsub|i>|)>>;

        <item>sampling <math|u> from <verbatim|uniform(0,1)>;

        <item>if <math|\<alpha\>\<gtr\>u>, then accept <math|x<rsub|i+1>>,
        <verbatim|accepted += 1>, and append it to <verbatim|chain>; else
        reject <math|x<rsub|i+1>>.
      </enumerate-numeric>

      <item>print accept-ratio by <verbatim|accepted / iterations>;

      <item>return <verbatim|chain>.
    </enumerate-numeric>
  </algorithm>

  <\theorem>
    <label|theorem: Metropolis>[Metropolis]
    <math|\<exists\>N<rsub|<text|burn-in>>\<gtr\>0> and large enough, s.t.
    samples <math|<around*|{|x<rsub|i>:i=N<rsub|<text|burn-in>>,\<ldots\>,<verbatim|<text|iterations>>|}>>
    generated by algorithm <reference|algorithm: Metropolis> approximately
    obeys the target distribution <math|p<around*|(|x|)>>. That is, algorithm
    <reference|algorithm: Metropolis> creates a sampler of
    <math|p<around*|(|x|)>>.
  </theorem>

  <\proof>
    For simplicity, let <math|<with|math-font|cal|X>> discrete. Consider any
    two state <math|s,r\<in\><with|math-font|cal|X>>. Let
    <math|p<around*|(|s|)>\<gtr\>p<around*|(|r|)>>. Consider an ensamble of a
    great number of identity stochastic systems. Let <math|n<around*|(|x|)>>
    the number of systems in state <math|x> within this ensamble. In the next
    iteration of Markov process, the number of systems transit
    <math|r\<rightarrow\>s> is

    <\equation*>
      n<around*|(|r|)>P<rsub|r,s>,
    </equation*>

    since <math|p<around*|(|s|)>/p<around*|(|r|)>\<gtr\>1> so that there's no
    rejection. However, because of rejection, the number of systems transit
    from <math|r\<rightarrow\>s> is not <math|n<around*|(|s|)>P<rsub|s,r>>
    any longer. Instead, since the probability of acceptance is
    <math|p<around*|(|r|)>/p<around*|(|s|)>> (by steps 3.3 and 3.4 in the
    algorithm), the number of systems transit from <math|r\<rightarrow\>s> is

    <\equation*>
      n<around*|(|s|)>P<rsub|s,r><frac|p<around*|(|r|)>|p<around*|(|s|)>>.
    </equation*>

    So, the net number of systems transit <math|r\<rightarrow\>s> is (recall
    <math|P<rsub|s,r>=P<rsub|r,s>>)

    <\equation*>
      P<rsub|r,s><around*|(|n<around*|(|r|)>-n<around*|(|s|)><frac|p<around*|(|r|)>|p<around*|(|s|)>>|)>.
    </equation*>

    So, if <math|n<around*|(|r|)>/n<around*|(|s|)>\<gtr\>p<around*|(|r|)>/p<around*|(|s|)>>,
    then there are systems transit <math|r\<rightarrow\>s>, so that
    <math|n<around*|(|r|)>> decreases and <math|n<around*|(|s|)>> increases.
    The same, if <math|n<around*|(|r|)>/n<around*|(|s|)>\<less\>p<around*|(|r|)>/p<around*|(|s|)>>,
    then there are systems transit <math|s\<rightarrow\>r>, so that
    <math|n<around*|(|s|)>> decreases and <math|n<around*|(|r|)>> increases.
    This process will reach an equilibrium where
    <math|n<around*|(|r|)>/n<around*|(|s|)>=p<around*|(|r|)>/p<around*|(|s|)>>.
    Now we proved that the states of the systems in the ensamble obey the
    target distribution <math|p>.

    To gain our conclusion, first consider that we re-do the algorithm
    <math|N> times, which in the equilibrium generates <math|N> samples, i.e.
    the <math|N> <math|x<rsub|N<rsub|<text|burn-in>>>>s. These samples obey
    the target distribution <math|p<around*|(|x|)>>. However, we can imagine
    all things in another way. We are to generate
    <math|N=<text|<verbatim|iterations>>-N<rsub|<text|burn-in>>> samples
    obeying <math|p<around*|(|x|)>> as follow. Do the algorithm one time,
    iterating from <math|x<rsub|0>> to <math|x<rsub|<text|<verbatim|iterations>>>>.
    Then, for the <math|i>th sample to generate by the algorithm, let
    <math|x<rsub|0>> in the algorithm be the
    <math|x<rsub|i+N<rsub|<text|burn-in>>>> we just generated. With this, we
    do the algorithm one time, but generate
    <math|N=<text|<verbatim|iterations>>-N<rsub|<text|burn-in>>> samples that
    obey <math|p<around*|(|x|)>>.
  </proof>
</body>

<initial|<\collection>
</collection>>

<\references>
  <\collection>
    <associate|algorithm: Metropolis|<tuple|1|?|../.TeXmacs/texts/scratch/no_name_1.tm>>
    <associate|theorem: Metropolis|<tuple|2|?|../.TeXmacs/texts/scratch/no_name_1.tm>>
  </collection>
</references>