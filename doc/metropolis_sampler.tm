<TeXmacs|1.99.1>

<style|generic>

<\body>
  <\hide-preamble>
    \;

    <assign||<macro|>>
  </hide-preamble>

  This documentation provides an illustration (and also a proof) of
  Metropolis sampler. The proof follows Metropolis et al (1953), but is
  modified and generalized in its morden face.

  <\notation>
    Let <math|x\<in\><with|math-font|cal|X>> any state of a given stochastic
    system. Let <math|p<around*|(|x|)>> denotes the target distribution to be
    mimicked. Let <math|P<rsub|x,y>> the proposed transition-distribution of
    Markov process from state <math|x> to <math|y> (i.e. the \Ppriori\Q in
    Metropolis et al (1953)), where <math|P<rsub|x,y>=P<rsub|y,x>> as
    demanded by Metripolis algorithm.
  </notation>

  <\algorithm>
    <label|algorithm: Metropolis>[Metropolis]

    <\render-code>
      """ Python3 code of Metropolis sampler.

      """

      \;

      import random

      \;

      class MetropolisSampler(object):

      \ \ \ \ 

      \ \ \ \ def __int__(self, iterations, initialize_state,
      markov_process):

      \ \ \ \ \ \ \ \ """ int * (None -\<gtr\> State) * (State -\<gtr\>
      State) -\<gtr\> None

      \ \ \ \ \ \ \ \ \ \ \ \ \ 

      \ \ \ \ \ \ \ \ \ \ \ \ \ The "State" can be any abstract class.

      \ \ \ \ \ \ \ \ """

      \ \ \ \ \ \ \ \ self.iterations = iterations

      \ \ \ \ \ \ \ \ self.initialize_state = initialize_state

      \ \ \ \ \ \ \ \ self.markov_process = markov_process

      \ \ \ \ \ \ \ \ 

      \ \ \ \ def __call__(self, target_distribution):

      \ \ \ \ \ \ \ \ """ (State -\<gtr\> float) -\<gtr\> [State]

      \ \ \ \ \ \ \ \ """

      \ \ \ \ \ \ \ \ 

      \ \ \ \ \ \ \ \ init_state = self.initialize_state()

      \ \ \ \ \ \ \ \ assert target_distribution(init_state) \<gtr\> 0

      \ \ \ \ \ \ \ \ 

      \ \ \ \ \ \ \ \ chain = [init_state]

      \ \ \ \ \ \ \ \ accepted = 0

      \;

      \ \ \ \ \ \ \ \ for i in range(self.iterations):

      \ \ \ \ \ \ \ \ \ \ \ \ 

      \ \ \ \ \ \ \ \ \ \ \ \ next_state = self.markov_process(init_state)

      \ \ \ \ \ \ \ \ \ \ \ \ alpha = target_distribution(next_state) /
      target_distribution(init_state)

      \ \ \ \ \ \ \ \ \ \ \ \ u = random.uniform(0, 1)

      \ \ \ \ \ \ \ \ \ \ \ \ 

      \ \ \ \ \ \ \ \ \ \ \ \ if alpha \<gtr\> u:

      \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ accepted += 1

      \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ chain.append(next_state)

      \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 

      \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ init_state = next_state.copy()

      \ \ \ \ \ \ \ \ \ \ \ \ 

      \ \ \ \ \ \ \ \ \ \ \ \ else:

      \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ pass

      \ \ \ \ \ \ \ \ 

      \ \ \ \ \ \ \ \ accept_ratio = accepted / self.iterations

      \ \ \ \ \ \ \ \ print('accept-ratio = {0}'.format(accept_ratio))

      \ \ \ \ \ \ \ \ 

      \ \ \ \ \ \ \ \ return chain
    </render-code>
  </algorithm>

  <\theorem>
    <label|theorem: Metropolis>[Metropolis]
    <math|\<exists\>N<rsub|<text|burn-in>>\<gtr\>0> and large enough, s.t.
    samples <math|<around*|{|x<rsub|i>:i=N<rsub|<text|burn-in>>,\<ldots\>,<verbatim|<text|iterations>>|}>>
    generated by algorithm <reference|algorithm: Metropolis> approximately
    obeys the target distribution <math|p<around*|(|x|)>>. That is, algorithm
    <reference|algorithm: Metropolis> creates a sampler of
    <math|p<around*|(|x|)>>.
  </theorem>

  <\proof>
    For simplicity, let <math|<with|math-font|cal|X>> discrete. Consider any
    two state <math|s,r\<in\><with|math-font|cal|X>>. Let
    <math|p<around*|(|s|)>\<gtr\>p<around*|(|r|)>>. Consider an ensamble of a
    great number of identity stochastic systems. Let <math|n<around*|(|x|)>>
    the number of systems in state <math|x> within this ensamble. In the next
    iteration of Markov process, the number of systems transit
    <math|r\<rightarrow\>s> is

    <\equation*>
      n<around*|(|r|)>P<rsub|r,s>,
    </equation*>

    since <math|p<around*|(|s|)>/p<around*|(|r|)>\<gtr\>1> so that there's no
    rejection. However, because of rejection, the number of systems transit
    from <math|r\<rightarrow\>s> is not <math|n<around*|(|s|)>P<rsub|s,r>>
    any longer. Instead, since the probability of acceptance is
    <math|p<around*|(|r|)>/p<around*|(|s|)>> (by steps 3.3 and 3.4 in the
    algorithm), the number of systems transit from <math|r\<rightarrow\>s> is

    <\equation*>
      n<around*|(|s|)>P<rsub|s,r><frac|p<around*|(|r|)>|p<around*|(|s|)>>.
    </equation*>

    So, the net number of systems transit <math|r\<rightarrow\>s> is (recall
    <math|P<rsub|s,r>=P<rsub|r,s>>)

    <\equation*>
      P<rsub|r,s><around*|(|n<around*|(|r|)>-n<around*|(|s|)><frac|p<around*|(|r|)>|p<around*|(|s|)>>|)>.
    </equation*>

    So, if <math|n<around*|(|r|)>/n<around*|(|s|)>\<gtr\>p<around*|(|r|)>/p<around*|(|s|)>>,
    then there are systems transit <math|r\<rightarrow\>s>, so that
    <math|n<around*|(|r|)>> decreases and <math|n<around*|(|s|)>> increases.
    The same, if <math|n<around*|(|r|)>/n<around*|(|s|)>\<less\>p<around*|(|r|)>/p<around*|(|s|)>>,
    then there are systems transit <math|s\<rightarrow\>r>, so that
    <math|n<around*|(|s|)>> decreases and <math|n<around*|(|r|)>> increases.
    This process will reach an equilibrium where
    <math|n<around*|(|r|)>/n<around*|(|s|)>=p<around*|(|r|)>/p<around*|(|s|)>>.
    Now we proved that the states of the systems in the ensamble obey the
    target distribution <math|p>.

    To gain our conclusion, first consider that we re-do the algorithm
    <math|N> times, which in the equilibrium generates <math|N> samples, i.e.
    the <math|N> <math|x<rsub|N<rsub|<text|burn-in>>>>s. These samples obey
    the target distribution <math|p<around*|(|x|)>>. However, we can imagine
    all things in another way. We are to generate
    <math|N=<text|<verbatim|iterations>>-N<rsub|<text|burn-in>>> samples
    obeying <math|p<around*|(|x|)>> as follow. Do the algorithm one time,
    iterating from <math|x<rsub|0>> to <math|x<rsub|<text|<verbatim|iterations>>>>.
    Then, for the <math|i>th sample to generate by the algorithm, let
    <math|x<rsub|0>> in the algorithm be the
    <math|x<rsub|i+N<rsub|<text|burn-in>>>> we just generated. With this, we
    do the algorithm one time, but generate
    <math|N=<text|<verbatim|iterations>>-N<rsub|<text|burn-in>>> samples that
    obey <math|p<around*|(|x|)>>.
  </proof>
</body>

<initial|<\collection>
</collection>>

<\references>
  <\collection>
    <associate|algorithm: Metropolis|<tuple|1|?>>
    <associate|theorem: Metropolis|<tuple|2|?>>
  </collection>
</references>