<TeXmacs|1.99.1>

<style|generic>

<\body>
  <\hide-preamble>
    \;

    <assign||<macro|>>
  </hide-preamble>

  This documentation provides an illustration (and also a proof) of
  Metropolis-Hastings algorithm of sampling. The proof follows Metropolis et
  al (1953), but is modified and generalized in its morden face.

  <\notation>
    Let <math|x\<in\><with|math-font|cal|X>> any state of a given stochastic
    system. Let <math|p<around*|(|x|)>> denotes the target distribution to be
    mimicked. Let <math|q<around*|(|x\<rightarrow\>y|)>> (or
    <math|q<around*|(|y\|x|)>> by statistics) the proposed
    transition-distribution of Markov process from state <math|x> to <math|y>
    (i.e. the \Ppriori\Q in Metropolis et al (1953)). Suppose, for any
    <math|x,y\<in\><with|math-font|cal|X>>,
    <math|q<around*|(|x\<rightarrow\>y|)>\<neq\>0> and
    <math|p<around*|(|x|)>\<neq\>0> (thus they are positive).
  </notation>

  <\algorithm>
    <label|algorithm: Metropolis>[Metropolis] (To-Do: needs modification form
    Metropolis to Metropolis-Hastrings.)

    <\render-code>
      """ Python3 code of Metropolis sampler.

      """

      \;

      import random

      \;

      class MetropolisSampler(object):

      \ \ \ \ 

      \ \ \ \ def __int__(self, iterations, initialize_state,
      markov_process):

      \ \ \ \ \ \ \ \ """ int * (None -\<gtr\> State) * (State -\<gtr\>
      State) -\<gtr\> None

      \ \ \ \ \ \ \ \ \ \ \ \ \ 

      \ \ \ \ \ \ \ \ \ \ \ \ \ The "State" can be any abstract class.

      \ \ \ \ \ \ \ \ """

      \ \ \ \ \ \ \ \ self.iterations = iterations

      \ \ \ \ \ \ \ \ self.initialize_state = initialize_state

      \ \ \ \ \ \ \ \ self.markov_process = markov_process

      \ \ \ \ \ \ \ \ 

      \ \ \ \ def __call__(self, target_distribution):

      \ \ \ \ \ \ \ \ """ (State -\<gtr\> float) -\<gtr\> [State]

      \ \ \ \ \ \ \ \ """

      \ \ \ \ \ \ \ \ 

      \ \ \ \ \ \ \ \ init_state = self.initialize_state()

      \ \ \ \ \ \ \ \ assert target_distribution(init_state) \<gtr\> 0

      \ \ \ \ \ \ \ \ 

      \ \ \ \ \ \ \ \ chain = [init_state]

      \ \ \ \ \ \ \ \ accepted = 0

      \;

      \ \ \ \ \ \ \ \ for i in range(self.iterations):

      \ \ \ \ \ \ \ \ \ \ \ \ 

      \ \ \ \ \ \ \ \ \ \ \ \ next_state = self.markov_process(init_state)

      \ \ \ \ \ \ \ \ \ \ \ \ alpha = target_distribution(next_state) /
      target_distribution(init_state)

      \ \ \ \ \ \ \ \ \ \ \ \ u = random.uniform(0, 1)

      \ \ \ \ \ \ \ \ \ \ \ \ 

      \ \ \ \ \ \ \ \ \ \ \ \ if alpha \<gtr\> u:

      \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ accepted += 1

      \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ chain.append(next_state)

      \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 

      \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ init_state = next_state.copy()

      \ \ \ \ \ \ \ \ \ \ \ \ 

      \ \ \ \ \ \ \ \ \ \ \ \ else:

      \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ pass

      \ \ \ \ \ \ \ \ 

      \ \ \ \ \ \ \ \ accept_ratio = accepted / self.iterations

      \ \ \ \ \ \ \ \ print('accept-ratio = {0}'.format(accept_ratio))

      \ \ \ \ \ \ \ \ 

      \ \ \ \ \ \ \ \ return chain
    </render-code>
  </algorithm>

  <\theorem>
    <label|theorem: Metropolis>[Metropolis-Hastrings]
    <math|\<exists\>N<rsub|<text|burn-in>>\<gtr\>0> and large enough, s.t.
    samples <math|<around*|{|x<rsub|i>:i=N<rsub|<text|burn-in>>,\<ldots\>,<verbatim|<text|iterations>>|}>>
    generated by algorithm <reference|algorithm: Metropolis> approximately
    obeys the target distribution <math|p<around*|(|x|)>>. That is, algorithm
    <reference|algorithm: Metropolis> creates a sampler of
    <math|p<around*|(|x|)>>.
  </theorem>

  <\proof>
    For simplicity, let <math|<with|math-font|cal|X>> discrete. Consider any
    two state <math|s,r\<in\><with|math-font|cal|X>>. Let
    <math|p<around*|(|s|)> q<around*|(|s\<rightarrow\>r|)>\<gtr\>p<around*|(|r|)>
    q<around*|(|r\<rightarrow\>s|)>>. Consider an ensamble of a great number
    of identity stochastic systems. Let <math|n<around*|(|x|)>> the number of
    systems in state <math|x> within this ensamble. In the next iteration of
    Markov process, the number of systems transit <math|r\<rightarrow\>s> is

    <\equation*>
      n<around*|(|r|)>q<around*|(|r\<rightarrow\>s|)>,
    </equation*>

    since <math|<around*|[|p<around*|(|s|)>
    q<around*|(|s\<rightarrow\>r|)>|]>/<around*|[|p<around*|(|r|)>
    q<around*|(|r\<rightarrow\>s|)>|]>\<gtr\>1> so that there's no rejection.
    However, because of rejection, the number of systems transit from
    <math|s\<rightarrow\>r> is not <math|n<around*|(|s|)>
    q<around*|(|s\<rightarrow\>r|)>> any longer. Instead, since the
    probability of acceptance is <math|<around*|[|p<around*|(|r|)>
    q<around*|(|r\<rightarrow\>s|)>|]>/<around*|[|p<around*|(|s|)>
    q<around*|(|s\<rightarrow\>r|)>|]>\<less\>1>, the number of systems
    transit from <math|s\<rightarrow\>r> is

    <\equation*>
      n<around*|(|s|)> q<around*|(|s\<rightarrow\>r|)> <frac|
      p<around*|(|r|)> q<around*|(|r\<rightarrow\>s|)>|p<around*|(|s|)>
      q<around*|(|s\<rightarrow\>r|)>>.
    </equation*>

    So, the net number of systems transit <math|r\<rightarrow\>s> is

    <\eqnarray*>
      <tformat|<table|<row|<cell|>|<cell|>|<cell|n<around*|(|r|)>q<around*|(|r\<rightarrow\>s|)>-n<around*|(|s|)>
      q<around*|(|s\<rightarrow\>r|)> <frac| p<around*|(|r|)>
      q<around*|(|r\<rightarrow\>s|)>|p<around*|(|s|)>
      q<around*|(|s\<rightarrow\>r|)>>>>|<row|<cell|>|<cell|=>|<cell|<frac|q<around*|(|r\<rightarrow\>s|)>|p<around*|(|s|)>>
      \<times\><around*|(|n<around*|(|r|)> p<around*|(|s|)>-n<around*|(|s|)>
      p<around*|(|r|)>|)>.>>>>
    </eqnarray*>

    So, if <math|n<around*|(|r|)> p<around*|(|s|)>-n<around*|(|s|)>
    p<around*|(|r|)>\<gtr\>0>, then there are systems transit
    <math|r\<rightarrow\>s> (since <math|q<around*|(|r\<rightarrow\>s|)>\<gtr\>0>
    and <math|p<around*|(|s|)>\<gtr\>0>), so that <math|n<around*|(|r|)>>
    decreases and <math|n<around*|(|s|)>> increases. The same, if
    <math|n<around*|(|r|)> p<around*|(|s|)>-n<around*|(|s|)>
    p<around*|(|r|)>\<less\>0>, then there are systems transit
    <math|s\<rightarrow\>r>, so that <math|n<around*|(|s|)>> decreases and
    <math|n<around*|(|r|)>> increases. This process will reach an equilibrium
    where <math|n<around*|(|r|)> p<around*|(|s|)>-n<around*|(|s|)>
    p<around*|(|r|)>=0>, i.e. <math|n<around*|(|r|)>/n<around*|(|s|)>=p<around*|(|r|)>/p<around*|(|s|)>>.
    Now we proved that the states of the systems in the ensamble obey the
    target distribution <math|p>.

    To gain our conclusion, first consider that we re-do the algorithm
    <math|N> times, which in the equilibrium generates <math|N> samples, i.e.
    the <math|N> <math|x<rsub|N<rsub|<text|burn-in>>>>s. These samples obey
    the target distribution <math|p<around*|(|x|)>>. However, we can imagine
    all things in another way. We are to generate
    <math|N=<text|<verbatim|iterations>>-N<rsub|<text|burn-in>>> samples
    obeying <math|p<around*|(|x|)>> as follow. Do the algorithm one time,
    iterating from <math|x<rsub|0>> to <math|x<rsub|<text|<verbatim|iterations>>>>.
    Then, for the <math|i>th sample to generate by the algorithm, let
    <math|x<rsub|0>> in the algorithm be the
    <math|x<rsub|i+N<rsub|<text|burn-in>>>> we just generated. With this, we
    do the algorithm one time, but generate
    <math|N=<text|<verbatim|iterations>>-N<rsub|<text|burn-in>>> samples that
    obey <math|p<around*|(|x|)>>.
  </proof>

  <\corollary>
    When, for <math|\<forall\>x,y\<in\><with|math-font|cal|X>>,
    <math|p<around*|(|x\<rightarrow\>y|)>=p<around*|(|y\<rightarrow\>x|)>>,
    the Metropolis-Hastings algorithm reduces to Metropolis algorithm (1953),
    where <math|\<alpha\><around*|(|x\<rightarrow\>y|)>=p<around*|(|y|)>/p<around*|(|x|)>>.
  </corollary>
</body>

<initial|<\collection>
</collection>>

<\references>
  <\collection>
    <associate|algorithm: Metropolis|<tuple|1|?>>
    <associate|theorem: Metropolis|<tuple|2|?>>
  </collection>
</references>